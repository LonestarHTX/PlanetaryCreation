# SIMD/GPU Implementation Review for PlanetaryCreation

Heck yes‚Äîit‚Äôs SIMD/GPU time üòà. I took a full pass over the repo and recent commits and pulled together a concrete plan with pointed changes (and a few ‚Äúdon‚Äôt do this to Future-You‚Äù notes). Below is what‚Äôs solid already, what I‚Äôd change before vectorizing, and then a step‚Äëby‚Äëstep path for a SIMD‚Äëfirst and GPU‚Äëfirst implementation you can pick from.

---

## Quick read of where things stand

- **Architecture is clean**: `UTectonicSimulationService` holds the canonical **double‚Äëprecision** state and advances the simulation; `FTectonicSimulationController` bridges to rendering, converts to floats, and feeds a **RealtimeMeshComponent** actor; everything runs entirely in the **editor**. Nice separation of concerns.
- **Recent work** added toggles without forced resets (LOD/heightmap), plus better snapshot logging in the controller. Good call for perf iteration.
- **Build loop shape**: the controller‚Äôs `BuildMeshFromSnapshot` iterates all render vertices, computes UVs (currently equirectangular), tangents, colors, etc. That‚Äôs going to be one of your hottest loops.
- **Data you expose is vectorization/gpu‚Äëfriendly**: `GetRenderVertices()`, `GetVertexPlateAssignments()`, `GetVertexElevationValues()`, `GetVertexAmplifiedElevation()`, `GetVertexRidgeDirections()`, `GetBoundaries()`, `GetSharedVertices()` are exactly the kind of flat arrays/buffers we want. Your tests also pin down expected behaviors (oceanic vs continental changes, determinism, etc.).
- **Stage‚ÄëB exemplar data**: a small library of 22 16‚Äëbit PNG / COG exemplars with corrected content paths‚Äîperfect candidates to pre-upload as a **Texture2DArray** on GPU.
- **RMC plugin**: good choice; it‚Äôs faster and more flexible than ProceduralMeshComponent and plays well with procedural/gigantic geometry. It supports stream updates, which we can exploit (update only positions/normals instead of rebuilding everything).

---

## Before you vectorize/offload: three small but high‚Äëleverage fixes

1. **Stop recomputing invariants per build**
   - The equirectangular UVs you compute from normalized vertex directions (in `BuildMeshFromSnapshot`) only depend on the unit direction and LOD topology‚Äî**not** on per‚Äëstep elevation. Precompute once per LOD and cache; then reuse when elevation changes.
   - Same for tangent seed (`UpVector`) heuristic‚Äîprecompute per vertex.

2. **Data layout for math-heavy passes (SoA > AoS)**
   - Anywhere you do large vector ops (`ComputeRidgeDirections`, elevation transforms, per‚Äëvertex color), store render-space geometry as **SoA** (`x[]`, `y[]`, `z[]`) for math; keep AoS (`FVector3f`) only for handoff to RMC. You‚Äôre already double in the service; use float SoA for render‚Äëside math to cut bandwidth in half. (You can still preserve doubles in the canonical state.)

3. **No logging in hot loops**
   - Some debug logs were added recently (good for diagnosing), but make sure they compile out in Development and never tick inside big loops. Wrap with `#if UE_BUILD_DEBUG` or a dedicated `CVar`.

---

## Path A ‚Äî SIMD‚Äëfirst (quick wins on CPU)

**Targets**: per‚Äëvertex transforms, ridge direction updates, Stage‚ÄëB amplification math (CPU path), colorization/packing.

1. **Threading first, then SIMD**
   - Wrap large loops with `ParallelFor` (or `UE::Tasks::ParallelForEach`) over contiguous blocks of vertex indices. Keep each block large enough (e.g., 8k‚Äì32k vertices) to amortize task overhead.

2. **Vectorize the math on float SoA buffers**
   - Convert `TArray<FVector3d>` ‚Üí temporary SoA `TArray<float>` for `x`, `y`, `z` (or keep a mirrored SoA that you refresh when LOD changes).
   - Normalize/cross/dot using AVX2/AVX‚Äë512 intrinsics **or** ISPC (easier). Typical pattern:
     - Load 8‚Äì16 `x`/`y`/`z` lanes
     - `rsqrt` normalize
     - Per‚Äëlane trig (`atan2`, `asin`) is the slow bit; batch it and consider an **approx** version or table where visual error is OK (UVs can tolerate approximation since they don‚Äôt drive physics).
   - UE doesn‚Äôt SIMD‚Äëaccelerate `FVector3d` operations; relying on `FMath` here won‚Äôt vectorize. Rolling your own with ISPC is pragmatic.

3. **ISPC drop‚Äëin (strongly recommended)**
   - Put a small **/Simd** folder with ISPC kernels for:
     - `ComputeRidgeDirections(float* x, float* y, float* z, float* out_rx, float* out_ry, float* out_rz, int N)`
     - `AmplifyElevationCPU(float* elevBase, float* rx, float* ry, float* rz, const uint16_t* exemplar, /*‚Ä¶*/, float* elevOut, int N)`
   - Compile with AVX2 (and AVX‚Äë512 if you want) and call from C++. This keeps your C++ clean and gets you auto‚Äëvectorization/gather/scatter without hand‚Äëwriting intrinsics.

4. **Avoid double in SIMD loops**
   - Keep doubles in the **service**; convert to float once per snapshot. AVX2 doubles cut your SIMD width in half for little visual upside. (Stick to doubles for steps where numerical drift matters‚Äîplate kinematics/accumulated transforms‚Äîthen down‚Äëcast.)

5. **Only update streams that changed**
   - With RMC, rebuild indices/topology only on LOD changes. For per‚Äëstep updates, update **position**, optional **color**, and **normal/tangent** streams. The recent code already computes tangents procedurally; that helps.

**What you‚Äôll likely see**: 2‚Äì6√ó speedup on per‚Äëvertex build paths and ridge updates on a modern desktop CPU, more if you were previously scalar and logging.

---

## Path B ‚Äî GPU‚Äëfirst (compute shader, minimal churn to your code)

You run in the **editor**, not PIE, and update geometry on demand‚Äînot 60 Hz‚Äîwhich is great for a GPU compute pass with read‚Äëback. The sweet spot is to offload **Stage‚ÄëB displacement synthesis** (the expensive exemplar sampling + blending) to a compute shader, then read back a single float buffer of **amplified elevation** to feed your existing RMC pipeline.

### 1) Prepare resources on the CPU side

- **Pre‚Äëupload exemplars** as a single `Texture2DArray` in PF_G16 or PF_R16F (PF_R16F is simpler on shader math). Use the paths in your fixed ExemplarLibrary JSON.
- Build per‚Äëvertex **inputs** as SRVs:
  - `StructuredBuffer<float3> UnitDir` (unit sphere directions of render vertices)
  - `StructuredBuffer<float> ElevBase` (base meters)
  - `StructuredBuffer<int> PlateId`
  - `StructuredBuffer<float3> RidgeDir` (if used by oceanic amplification)
  - Optional: `StructuredBuffer<float2> UVPrecomputed` (if you decide not to recompute UVs on GPU)

You already compute the equirectangular mapping in C++; mirror that math in HLSL, or better, precompute once per LOD and pass `TexCoord` as input.

### 2) A single compute pass

Create a global shader `FStageBAmplifyCS` with parameters:

```hlsl
// StageBAmplifyCS.usf
RWStructuredBuffer<float> OutAmplifiedElevation;

StructuredBuffer<float3> UnitDir;          // render vertex directions
StructuredBuffer<float>  ElevBase;         // base elevation (m)
StructuredBuffer<int>    PlateId;          // for continental vs oceanic/mixing
StructuredBuffer<float3> RidgeDir;         // oceanic ridge influence

Texture2DArray<float>    Exemplars;        // PF_R16F texture array
SamplerState             ExemplarSampler;

cbuffer Params {
  float ElevScale;
  float OceanicStrength;
  float ContinentalStrength;
  uint  NumExemplars;
  uint  UseOceanic;
  uint  UseContinental;
  // ... any weighting/LOD thresholds
};

[numthreads(128,1,1)]
void Main(uint3 DTid : SV_DispatchThreadID)
{
    uint i = DTid.x;
    // 1) Optional: derive UV from UnitDir[i] (equirectangular)
    // 2) Select exemplar index / weights (simple heuristic or precomputed indirection)
    // 3) Sample & blend exemplars
    // 4) Write OutAmplifiedElevation[i] = ElevBase[i] + AmplifiedDelta;
}
```

Wire it with RDG in your editor module:

```cpp
// FStageBAmplifyCS::FParameters* P = GraphBuilder.AllocParameters<...>();
// Fill SRVs/UAVs, add pass, then EnqueueCopy to a readback buffer.
// On completion, copy back into your TArray<float> VertexAmplifiedElevation and proceed with RMC build.
```

(You‚Äôll need `RenderCore`, `RHI`, and a small `Shaders` dir added in `PlanetaryCreationEditor.Build.cs`. RMC will happily take the updated float elevations and you can reuse your existing mesh build path.)

### 3) Where to begin offloading

- **Stage‚ÄëB only** first (low risk): one buffer in, one buffer out, minimal changes elsewhere.
- If that goes well, consider also computing **normals** in a second compute pass from the displaced positions (or from a neighbors table) and avoid CPU normal recompute entirely.

### 4) Read‚Äëback isn‚Äôt scary here

You‚Äôre stepping in multi‚Äëmillion‚Äëyear increments, not at frame rate. A one‚Äëtime GPU compute + read‚Äëback per step is fine UX‚Äëwise in the editor. (If/when you want real‚Äëtime camera‚Äëdriven updates, keep the displacement on‚ÄëGPU and drive it in the vertex factory/material, but that‚Äôs a bigger plumbing change.)

---

## Specific ‚Äúchange this‚Äù items with file pointers

- **Precompute UVs/tangents** instead of per‚Äëbuild recompute  
  In `FTectonicSimulationController::BuildMeshFromSnapshot`, UVs are currently derived per vertex right before adding to the stream set. Persist them alongside render vertices per LOD and reuse.

- **Keep doubles in the service, float everywhere else**  
  The design intentionally uses doubles in the service to avoid drift; keep it. But snapshots feeding RMC should be in float SoA and reused across frames.

- **Boundary data** (`TMap<TPair<int32,int32>, FPlateBoundary>`) is not GPU‚Äëfriendly  
  If `ComputeRidgeDirections()` depends on it, generate a **flat ‚Äúsegments‚Äù array** (CSR‚Äëstyle) next to the map so both SIMD and GPU can iterate without hashing or branching on map lookups. The tests already read `GetBoundaries()` & `GetSharedVertices()`; add a `GetBoundarySegments()` that returns contiguous memory.

- **Hot loop hygiene**  
  The debug prints added to `CreateMeshBuildSnapshot()` are helpful while stabilizing, but ensure they‚Äôre compiled out. (They‚Äôre inside `if` guards now‚Äîjust make sure it doesn‚Äôt sneak into release builds.)

- **Exemplar IO**  
  You fixed pathing in `ExemplarLibrary.json`; at editor startup (or first enable of continental/oceanic amp), load PNG16s into `UTexture2D` and keep them resident. One trip to GPU, then never touch disk while stepping.

---

## Suggested implementation order (lowest effort ‚Üí highest payoff)

1. **Cache invariants** (UVs, tangent seeds) and **swap to SoA** for render‚Äëside arrays.  
2. **ParallelFor** the big loops; keep per‚Äëtask blocks large.  
3. **ISPC** kernels for ridge directions & Stage‚ÄëB math on CPU.  
4. **GPU Stage‚ÄëB compute** as a single pass with read‚Äëback of one float buffer.  
5. Optional: **GPU normals** pass, then CPU only stitches RMC streams.  
6. Optional (advanced): move displacement to a custom vertex factory/material to avoid read‚Äëbacks for real‚Äëtime camera‚Äëdriven LOD.

---

## Guardrails & tests (so we don‚Äôt regress science or visuals)

- Reuse your automation tests (Continental/Oceanic amplification, determinism %, variance checks). Add one more test for **float vs double parity** on small meshes; assert `max|Œîelev| < 1e‚Äë3` m at LOD 5 for a fixed seed.
- Add quick timers around: `CreateMeshBuildSnapshot`, `BuildMeshFromSnapshot`, and (new) `RunStageBAmplifyCS`. Use Unreal Insights to verify we‚Äôre not on the game/editor thread during heavy lifting.

---

## Gotchas to plan around

- **Double‚Äëprecision SIMD**: painful and rarely worth it for visuals. If a specific tectonic integration truly needs doubles, keep that CPU‚Äëscalar (or vectorize where possible) and downcast at snapshot time.
- **Divergent branches** in GPU compute (continental vs oceanic vs boundary): use permutations or per‚Äëmask kernels to keep warps coherent rather than one giant `if` soup.
- **RMC update granularity**: update only the changed streams; avoid recreating sections. RMC supports fine‚Äëgrained stream updates.

---

## TL;DR / Punch list

- [ ] Precompute & cache UV/tangent seeds per LOD (no per‚Äëbuild trig).  
- [ ] Mirror render arrays to **float SoA**; keep doubles only in the service.  
- [ ] `ParallelFor` large vertex loops; remove logs in hot paths.  
- [ ] Add **ISPC** kernels for ridge dirs + Stage‚ÄëB math on CPU.  
- [ ] Upload 22 exemplars once ‚Üí `Texture2DArray`; implement **`FStageBAmplifyCS`** compute pass; read back one float buffer.  
- [ ] Consider GPU normals as a second pass.  
- [ ] Keep RMC index/topology static across steps; update only position/normal/color streams.

---

*If you‚Äôre leaning CPU‚Äëfirst, start with ISPC kernels and ParallelFor. If you‚Äôre itching to jump straight to GPU, begin with `FStageBAmplifyCS` and the texture array upload‚Äîthose two pieces will give you the biggest swing with minimal disruption.*

